{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d9cca8",
   "metadata": {},
   "source": [
    "# 数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eff668",
   "metadata": {},
   "source": [
    "## N维数组\n",
    "N维数组是机器学习和神经网络的主要数据结构  \n",
    "\n",
    "<img src=\"img/N维数组样例1.png\" align=\"left\" width=\"600\">\n",
    "<img src=\"img/N维数组样例2.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc4aea",
   "metadata": {},
   "source": [
    "## 访问元素\n",
    "<img src=\"img/访问元素.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea837d8",
   "metadata": {},
   "source": [
    "## 数据操作实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28c746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\projects\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c13a6",
   "metadata": {},
   "source": [
    "### 创建张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ca68d",
   "metadata": {},
   "source": [
    "张量表示一个数值组成的数组，这个数组可能有多个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5795a453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31a5c4",
   "metadata": {},
   "source": [
    "可以通过张量的`shape`属性来访问张量的形状和张量中元素的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5591d639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e60055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdae08",
   "metadata": {},
   "source": [
    "`reshape`函数可以改变一个张量的形状而不改变元素数量和元素值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85323377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0edc69",
   "metadata": {},
   "source": [
    "使用全0、全1、其他常量或者从特定分布中随机采样的数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc190a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0af3544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805101a2",
   "metadata": {},
   "source": [
    "通过python列表（或嵌套列表）创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac94739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb3e53",
   "metadata": {},
   "source": [
    "### 张量运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5d08e",
   "metadata": {},
   "source": [
    "常见的标准算数运算符（`+`,`-`,`*`,`/`和`**`）都可以被升级为按元素运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ff0a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0,2,4,8])\n",
    "y = torch.tensor([2,2,2,2])\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193845e",
   "metadata": {},
   "source": [
    "把多个张量连结在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b15820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12,dtype=torch.float32).reshape((3,4))\n",
    "y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "torch.cat((x,y),dim=0),torch.cat((x,y),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a2b01",
   "metadata": {},
   "source": [
    "通过逻辑运算符构建二元张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55841c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae4c88",
   "metadata": {},
   "source": [
    "对张量中的所有元素求和会产生一个只有一个元素的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b717a870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae9123",
   "metadata": {},
   "source": [
    "### 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71de59",
   "metadata": {},
   "source": [
    "即使形状不同，我们仍然可以通过调用**广播机制**来执行按元素操作（张量的维度需要一致）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a28202a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3,1))\n",
    "b = torch.arange(2).reshape((1,2))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744b51e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 相当于把a和b都复制成3*2的矩阵\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624b970",
   "metadata": {},
   "source": [
    "### 索引操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4238df1e",
   "metadata": {},
   "source": [
    "可以用`[-1]`选择最后一个元素，用`[1:3]`选择第二个和第三个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fea72ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a128bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61dcdf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f6651",
   "metadata": {},
   "source": [
    "除读取外，我们还可以通过指定索引来将元素写入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31836e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2] = 9\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc99602",
   "metadata": {},
   "source": [
    "为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3ad7be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2,:] = 12\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6dbb04",
   "metadata": {},
   "source": [
    "### 节省内存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c278fc1",
   "metadata": {},
   "source": [
    "运行一些操作可能会导致为新结果分配内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccf80c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(y)\n",
    "y = y + x\n",
    "id(y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429e52f",
   "metadata": {},
   "source": [
    "执行原地操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4e179ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z):2370418295088\n",
      "id(z):2370418295088\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros_like(y)\n",
    "print(f'id(z):{id(z)}')\n",
    "z[:] = x + y\n",
    "print(f'id(z):{id(z)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a1d5ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26., 25., 28., 27.],\n",
       "        [25., 26., 27., 28.],\n",
       "        [20., 21., 22., 23.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d96fcd",
   "metadata": {},
   "source": [
    "如果在后续计算中没有重复使用x，我们也可以使用`x[:]=x+y`或`x += y `来减少操作的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff46273f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(x)\n",
    "x += y\n",
    "id(x) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ef27f",
   "metadata": {},
   "source": [
    "### 类型转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3e0e2",
   "metadata": {},
   "source": [
    "转换为numpy张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65c2bac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = x.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A),type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58280d56",
   "metadata": {},
   "source": [
    "将大小为1的张量转换为python标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acf6d5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6955f45",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f447430",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc22c5e",
   "metadata": {},
   "source": [
    "创建一个人工数据集，并存储在csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6824dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..','data'),exist_ok=True)\n",
    "data_file = os.path.join('..','data','house_tiny.csv')\n",
    "with open(data_file,'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')    # 列名\n",
    "    f.write('NA,Pave,127500\\n')    # 每行表示一个数据样本\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e13e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6bc55",
   "metadata": {},
   "source": [
    "## 处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272973c",
   "metadata": {},
   "source": [
    "为了处理缺失的数据，典型的方法包括**插值**和**删除**，这里我们将考虑插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72fe72b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaoyu\\AppData\\Local\\Temp\\ipykernel_14272\\926360299.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  inputs = inputs.fillna(inputs.mean())\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:,0:2], data.iloc[:,2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6015a79",
   "metadata": {},
   "source": [
    "对于`inputs`中的类别值或离散值，我们将'NaN'视为一个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ff887f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs,dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e8671",
   "metadata": {},
   "source": [
    "现在`inputs`和`outputs`中的所有条目都是数值类型，它们可以转换为张量格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca207560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571db5c3",
   "metadata": {},
   "source": [
    "# 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9103b97c",
   "metadata": {},
   "source": [
    "<img src=\"img/线性代数1.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea435d1",
   "metadata": {},
   "source": [
    "## 标量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade17b59",
   "metadata": {},
   "source": [
    "<img src=\"img/标量.png\" align=\"left\" width=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c55fd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "x + y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48220103",
   "metadata": {},
   "source": [
    "## 向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f8274",
   "metadata": {},
   "source": [
    "<img src=\"img/向量.png\" align=\"left\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b665db",
   "metadata": {},
   "source": [
    "<img src=\"img/向量2.png\" align=\"left\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b357c",
   "metadata": {},
   "source": [
    "<img src=\"img/向量3.png\" align=\"left\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f9104a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723d0eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74216603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问张量的长度\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56dd9fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只有一个轴的张量，形状只有一个元素\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cb961",
   "metadata": {},
   "source": [
    "## 矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a34a61",
   "metadata": {},
   "source": [
    "<img src=\"img/矩阵1.png\" align=\"left\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5eae5",
   "metadata": {},
   "source": [
    "<img src=\"img/矩阵2.png\" align=\"left\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e048a",
   "metadata": {},
   "source": [
    "<img src=\"img/矩阵3.png\" align=\"left\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4bf81",
   "metadata": {},
   "source": [
    "<img src=\"img/矩阵4.png\" align=\"left\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d547178",
   "metadata": {},
   "source": [
    "### 特殊矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6206d6",
   "metadata": {},
   "source": [
    "<img src=\"img/特殊矩阵1.png\" align=\"left\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7912eaa",
   "metadata": {},
   "source": [
    "<img src=\"img/特殊矩阵2.png\" align=\"left\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2772f",
   "metadata": {},
   "source": [
    "<img src=\"img/特殊矩阵3.png\" align=\"left\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae601d",
   "metadata": {},
   "source": [
    "<img src=\"img/特征向量和特征值.png\" align=\"left\" width=\"550\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03b23bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be6143f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵转置\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f82f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对称矩阵\n",
    "B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03e6e03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c915c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape((2,3,4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb099d",
   "metadata": {},
   "source": [
    "给定具有相同形状的任何两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd216d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone()    \n",
    "A ,A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1cbe1",
   "metadata": {},
   "source": [
    "两个矩阵的按元素乘法称为**哈达玛积**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4687c27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a870602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "a,X,a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf50bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.],\n",
       "          [16., 17., 18., 19.]],\n",
       " \n",
       "         [[20., 21., 22., 23.],\n",
       "          [24., 25., 26., 27.],\n",
       "          [28., 29., 30., 31.],\n",
       "          [32., 33., 34., 35.],\n",
       "          [36., 37., 38., 39.]]]),\n",
       " torch.Size([2, 5, 4]),\n",
       " tensor(780.))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算任意形状张量的元素和\n",
    "A = torch.arange(40,dtype=torch.float32).reshape(2,5,4)\n",
    "A, A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee242091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20, 22, 24, 26],\n",
       "         [28, 30, 32, 34],\n",
       "         [36, 38, 40, 42],\n",
       "         [44, 46, 48, 50],\n",
       "         [52, 54, 56, 58]]),\n",
       " torch.Size([5, 4]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定求和汇总张量的轴\n",
    "A_sum_axis_0 = A.sum(axis=0)\n",
    "A_sum_axis_0, A_sum_axis_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2067a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 40,  45,  50,  55],\n",
       "         [140, 145, 150, 155]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis_1 = A.sum(axis=1)\n",
    "A_sum_axis_1, A_sum_axis_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "436a5c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([180, 190, 200, 210])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941c918",
   "metadata": {},
   "source": [
    "一个与求和相关的量是**平均值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff053c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(19.5000), tensor(19.5000))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5550beef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10., 11., 12., 13.],\n",
       "         [14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21.],\n",
       "         [22., 23., 24., 25.],\n",
       "         [26., 27., 28., 29.]]),\n",
       " tensor([[10., 11., 12., 13.],\n",
       "         [14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21.],\n",
       "         [22., 23., 24., 25.],\n",
       "         [26., 27., 28., 29.]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb32f8",
   "metadata": {},
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24b44aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 40.,  45.,  50.,  55.]],\n",
       "\n",
       "        [[140., 145., 150., 155.]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1,keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a68532",
   "metadata": {},
   "source": [
    "通过广播将A除以sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dadeaf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0222, 0.0400, 0.0545],\n",
       "         [0.1000, 0.1111, 0.1200, 0.1273],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.3000, 0.2889, 0.2800, 0.2727],\n",
       "         [0.4000, 0.3778, 0.3600, 0.3455]],\n",
       "\n",
       "        [[0.1429, 0.1448, 0.1467, 0.1484],\n",
       "         [0.1714, 0.1724, 0.1733, 0.1742],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2286, 0.2276, 0.2267, 0.2258],\n",
       "         [0.2571, 0.2552, 0.2533, 0.2516]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100889dd",
   "metadata": {},
   "source": [
    "某个轴计算A元素的累计总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf7df56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]],\n",
       "\n",
       "        [[20., 22., 24., 26.],\n",
       "         [28., 30., 32., 34.],\n",
       "         [36., 38., 40., 42.],\n",
       "         [44., 46., 48., 50.],\n",
       "         [52., 54., 56., 58.]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d6ff7",
   "metadata": {},
   "source": [
    "点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21cc81ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4,dtype=torch.float32)\n",
    "y = torch.ones(4,dtype=torch.float32)\n",
    "x, y, torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba2ea9",
   "metadata": {},
   "source": [
    "矩阵向量积Ax是一个长度为m的列向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19549fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "A.shape, x.shape,torch.mv(A,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e2a91",
   "metadata": {},
   "source": [
    "矩阵乘法AB可以看作是简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n*m矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9151044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(4,3)\n",
    "torch.mm(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d39b4d0",
   "metadata": {},
   "source": [
    "L2范数是向量元素平方和的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5833781d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0,-4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56012247",
   "metadata": {},
   "source": [
    "L1范数是向量元素的绝对值之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28e671e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21eac09",
   "metadata": {},
   "source": [
    "矩阵的佛罗贝尼乌斯范数是矩阵元素的平方和的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54ceb2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d942d",
   "metadata": {},
   "source": [
    "# 矩阵计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8619e3e6",
   "metadata": {},
   "source": [
    "## 导数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea7307",
   "metadata": {},
   "source": [
    "<img src=\"img/标量导数1.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa5890",
   "metadata": {},
   "source": [
    "<img src=\"img/标量导数2.png\" align=\"left\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def4d6e",
   "metadata": {},
   "source": [
    "<img src=\"img/亚导数1.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ea4a2",
   "metadata": {},
   "source": [
    "<img src=\"img/亚导数2.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60eea7b",
   "metadata": {},
   "source": [
    "## 梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6743b",
   "metadata": {},
   "source": [
    "<img src=\"img/梯度1.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab2c1a",
   "metadata": {},
   "source": [
    "1. y是标量，x是列向量，导数是一个行向量  \n",
    "\n",
    "<img src=\"img/梯度2.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d821f",
   "metadata": {},
   "source": [
    "<img src=\"img/梯度3.png\" align=\"left\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73501df0",
   "metadata": {},
   "source": [
    "2. y是列向量，x是标量，导数是一个列向量  \n",
    "\n",
    "<img src=\"img/梯度4.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9003e2",
   "metadata": {},
   "source": [
    "3. y是列向量，x是列向量，导数是一个矩阵  \n",
    "\n",
    "<img src=\"img/梯度5.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ed055",
   "metadata": {},
   "source": [
    "# 自动求导"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90deafee",
   "metadata": {},
   "source": [
    "<img src=\"img/自动求导1.png\" align=\"left\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca4083",
   "metadata": {},
   "source": [
    "## 计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2f734",
   "metadata": {},
   "source": [
    "<img src=\"img/计算图.png\" align=\"left\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073cb33c",
   "metadata": {},
   "source": [
    "## 自动求导的两种模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e40704",
   "metadata": {},
   "source": [
    "<img src=\"img/自动求导2.png\" align=\"left\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fba31",
   "metadata": {},
   "source": [
    "<img src=\"img/反向累积.png\" align=\"left\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e11bb663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90c0dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储梯度\n",
    "x.requires_grad_(True)\n",
    "x.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "94c0a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2*torch.dot(x,x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b32c002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过反向传播函数来自动计算y关于x每个分量的梯度\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b1396c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34b4c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，pytorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d414c8",
   "metadata": {},
   "source": [
    "在深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3e41a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x*x\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212763a",
   "metadata": {},
   "source": [
    "将某些计算移动到记录的计算图之外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a6ccdc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x*x\n",
    "u = y.detach()\n",
    "z = u*x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5553aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20bdac9",
   "metadata": {},
   "source": [
    "此外，即使构建函数的计算图需要通过python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ef684e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a):\n",
    "    b = a*2\n",
    "    while b.norm()<1000:\n",
    "        b=b*2\n",
    "    if b.sum()>0:\n",
    "        c=b\n",
    "    else:\n",
    "        c=100*b\n",
    "    return c\n",
    "\n",
    "a = torch.randn(size=(),requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "\n",
    "a.grad == d/a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projects)",
   "language": "python",
   "name": "projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
